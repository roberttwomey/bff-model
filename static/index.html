<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
  <title>Jetson LLM Voice Chat (VAD)</title>
  <style>
    :root { color-scheme: dark; }
    body { margin:0; font-family: system-ui,-apple-system,Segoe UI,Roboto,sans-serif; background:#0b0c0f; color:#e7e7ea; }
    .wrap { max-width: 820px; margin: 0 auto; padding: 16px; }
    header { display:flex; gap:8px; align-items:center; margin-bottom:12px; }
    input, select, button {
      background:#14161b; color:#e7e7ea; border:1px solid #2a2e36; border-radius:12px; padding:10px 12px; outline:none;
    }
    button { cursor:pointer; }
    .row { display:flex; gap:8px; align-items:center; flex-wrap:wrap; }
    .row > * { flex: 1 1 auto; }
    .chat { display:flex; flex-direction:column; gap:10px; margin-top:10px; padding-bottom:126px; }
    .bubble {
      position:relative; max-width:78%; padding:12px 14px; border-radius:16px; line-height:1.35;
      box-shadow:0 1px 2px rgba(0,0,0,0.25); white-space:pre-wrap;
    }
    .me  { align-self:flex-end; background:#2a2e36; }
    .bot { align-self:flex-start; background:#1a1d24; }
    .sys { align-self:center; opacity:0.8; font-size:12px; }
    .speak-btn {
      position:absolute; right:8px; bottom:8px; font-size:14px; opacity:0.8;
      border:1px solid #2a2e36; border-radius:999px; padding:2px 8px; background:#14161b;
    }
    .footer {
      position:fixed; bottom:0; left:0; right:0; background:rgba(11,12,15,0.95); backdrop-filter:blur(6px);
      border-top:1px solid #2a2e36; padding:8px;
    }
    .footer .row { gap:6px; }
    .pill { font-size:12px; opacity:0.9; padding:6px 8px; border-radius:99px; border:1px solid #2a2e36; }
    .vad.on { background:#0d5; color:#031; border-color:#0b4; }
    .vad.off { background:#555; color:#ddd; border-color:#333; }
    .vad.state { font-weight:600; }
    .hint { font-size:12px; opacity:0.8; margin-top:6px; }
    .small { font-size:12px; opacity:0.7; }
    .tts-row { gap:8px; margin-top:8px; align-items:center; }
    .tts-row > * { flex:0 0 auto; }
    label { font-size:12px; opacity:0.9; }
    .slider { width:120px; }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <strong>Jetson LLM Voice Chat</strong>
      <span class="pill">VAD</span>
      <span id="vadState" class="pill vad state off">Idle</span>
    </header>

    <div class="row" style="margin-bottom:8px">
      <input id="server" placeholder="Server (e.g., http://192.168.4.23:8000)" />
      <input id="model" placeholder="Model (optional, e.g., llama3.2:3b)" />
      <button id="save">Save</button>
    </div>
    <div class="small">Tap ‚Äúüé§ Start VAD‚Äù once to grant mic permission. The page will listen, auto-start on voice, and auto-stop on silence (~0.6‚Äì1s).</div>

    <!-- TTS controls -->
    <div class="row tts-row">
      <label><input type="checkbox" id="speakToggle" checked /> üîä Speak replies</label>
      <label>Voice:
        <select id="voiceSelect"></select>
      </label>
      <label>Rate:
        <input id="rate" class="slider" type="range" min="0.6" max="1.4" step="0.05" value="1.0">
        <span id="rateVal" class="small">1.00</span>
      </label>
      <label>Pitch:
        <input id="pitch" class="slider" type="range" min="0.6" max="1.6" step="0.05" value="1.0">
        <span id="pitchVal" class="small">1.00</span>
      </label>
    </div>

    <div id="chat" class="chat"></div>
  </div>

  <div class="footer">
    <div class="wrap">
      <div class="row">
        <button id="toggleVAD" class="pill vad off">üé§ Start VAD</button>
        <input id="text" placeholder="Type message‚Ä¶" />
        <button id="send">Send</button>
      </div>
      <div class="hint" id="hint">Status: not listening.</div>
    </div>
  </div>

<script>
/* ------------------------- UI refs ------------------------- */
const el = (id) => document.getElementById(id);
const chatEl   = el('chat');
const srvEl    = el('server');
const modelEl  = el('model');
const saveBtn  = el('save');
const txtEl    = el('text');
const sendBtn  = el('send');
const hintEl   = el('hint');

const toggleVADBtn = el('toggleVAD');
const vadStatePill = el('vadState');

const speakToggle = el('speakToggle');
const voiceSelect = el('voiceSelect');
const rateSlider  = el('rate');   const rateVal  = el('rateVal');
const pitchSlider = el('pitch');  const pitchVal = el('pitchVal');

const storage = {
  get server(){ return localStorage.getItem('server') || `${location.origin}`; },
  set server(v){ localStorage.setItem('server', v); },
  get model(){ return localStorage.getItem('model') || ''; },
  set model(v){ localStorage.setItem('model', v); },
  get history(){ try{ return JSON.parse(localStorage.getItem('history')||'[]'); } catch{ return []; } },
  set history(v){ localStorage.setItem('history', JSON.stringify(v)); },
  get speak(){ return localStorage.getItem('speak') !== 'false'; },
  set speak(v){ localStorage.setItem('speak', String(v)); },
  get voiceURI(){ return localStorage.getItem('voiceURI') || ''; },
  set voiceURI(v){ localStorage.setItem('voiceURI', v); },
  get rate(){ return parseFloat(localStorage.getItem('rate') || '1.0'); },
  set rate(v){ localStorage.setItem('rate', String(v)); },
  get pitch(){ return parseFloat(localStorage.getItem('pitch') || '1.0'); },
  set pitch(v){ localStorage.setItem('pitch', String(v)); },
};

srvEl.value   = storage.server;
modelEl.value = storage.model;

let history = storage.history.length ? storage.history : [
  { role: "system", content: "You are a concise, helpful assistant running on an embedded robot/edge device. Keep answers short." }
];
renderAll();

/* ------------------------- TTS helpers ------------------------- */
function loadVoicesIntoSelect() {
  const voices = speechSynthesis.getVoices();
  voiceSelect.innerHTML = '';
  voices.forEach(v => {
    const opt = document.createElement('option');
    opt.value = v.voiceURI;
    opt.textContent = `${v.name} (${v.lang})`;
    voiceSelect.appendChild(opt);
  });
  const saved = storage.voiceURI;
  if (saved && voices.some(v => v.voiceURI === saved)) {
    voiceSelect.value = saved;
  } else if (voices[0]) {
    voiceSelect.value = voices[0].voiceURI;
    storage.voiceURI = voices[0].voiceURI;
  }
}
function currentVoice() {
  const uri = voiceSelect.value;
  return speechSynthesis.getVoices().find(v => v.voiceURI === uri) || null;
}
function speak(text) {
  try {
    if (!speakToggle.checked || !text) return;
    const u = new SpeechSynthesisUtterance(text);
    const v = currentVoice();
    if (v) u.voice = v;
    u.rate  = parseFloat(rateSlider.value || '1.0');
    u.pitch = parseFloat(pitchSlider.value || '1.0');
    speechSynthesis.cancel();
    speechSynthesis.speak(u);
  } catch (e) {}
}
document.addEventListener('touchstart', () => { try { speechSynthesis.cancel(); } catch(_){} }, { once:true });
if ('speechSynthesis' in window) {
  loadVoicesIntoSelect();
  window.speechSynthesis.onvoiceschanged = loadVoicesIntoSelect;
  speakToggle.checked = storage.speak;
  rateSlider.value  = storage.rate;  rateVal.textContent  = storage.rate.toFixed(2);
  pitchSlider.value = storage.pitch; pitchVal.textContent = storage.pitch.toFixed(2);
}
voiceSelect.onchange = () => { storage.voiceURI = voiceSelect.value; };
speakToggle.onchange = () => { storage.speak = speakToggle.checked; };
rateSlider.oninput  = () => { rateVal.textContent  = parseFloat(rateSlider.value).toFixed(2); storage.rate  = parseFloat(rateSlider.value); };
pitchSlider.oninput = () => { pitchVal.textContent = parseFloat(pitchSlider.value).toFixed(2); storage.pitch = parseFloat(pitchSlider.value); };

/* ------------------------- Chat UI ------------------------- */
function renderAll(){
  chatEl.innerHTML = "";
  history.forEach((msg) => appendBubble(msg.role, msg.content));
  chatEl.scrollTop = chatEl.scrollHeight;
}
function appendBubble(role, text){
  const div = document.createElement('div');
  div.className = 'bubble ' + (role === 'user' ? 'me' : role === 'assistant' ? 'bot' : 'sys');
  div.textContent = text;
  if (role === 'assistant') {
    const b = document.createElement('button');
    b.className = 'speak-btn';
    b.title = 'Speak this response';
    b.textContent = 'üîä';
    b.onclick = (e) => { e.stopPropagation(); speak(text); };
    div.appendChild(b);
  }
  chatEl.appendChild(div);
  chatEl.scrollTop = chatEl.scrollHeight;
}

/* ------------------------- Networking ------------------------- */
async function sendToJetson(userText){
  const server = srvEl.value.replace(/\/+$/, '');
  const model  = modelEl.value.trim() || null;
  const payload = { messages: history, model };
  payload.messages.push({ role: "user", content: userText });

  const url = server + "/chat";
  const res = await fetch(url, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(payload)
  });
  if(!res.ok) throw new Error(await res.text());
  const data = await res.json();
  const reply = data.reply || "";
  history.push({ role:"user", content:userText });
  history.push({ role:"assistant", content:reply });
  localStorage.setItem('history', JSON.stringify(history));
  return reply;
}
sendBtn.onclick = async () => {
  const text = txtEl.value.trim();
  if(!text) return;
  txtEl.value = "";
  appendBubble('user', text);
  try {
    const reply = await sendToJetson(text);
    appendBubble('assistant', reply);
    speak(reply);
  } catch(err){
    appendBubble('system', 'Error: ' + err.message);
  }
};
txtEl.addEventListener('keydown', (e) => { if(e.key === 'Enter') sendBtn.click(); });
saveBtn.onclick = () => {
  localStorage.setItem('server', srvEl.value);
  localStorage.setItem('model', modelEl.value);
  appendBubble('system', 'Saved server/model.');
};

/* ------------------------- WebAudio VAD + Recorder ------------------------- */
/* Simple energy-based VAD:
   - Measure RMS over frames from an AnalyserNode
   - Start recording when dB > START_DB for START_FRAMES
   - Stop when dB < STOP_DB for STOP_FRAMES (hangover)
   Tune thresholds below for your environment.
*/
const VAD_CFG = {
  pollMs: 40,          // analysis hop
  startDb: -45,        // dBFS above which we consider "speech started"
  stopDb:  -52,        // dBFS below which we consider "silence"
  startFrames: 3,      // need N consecutive frames above startDb
  stopFrames:  15,     // need N consecutive frames below stopDb (~600ms at 40ms hop)
  minSpeakMs: 400,     // ignore too-short bursts
};

let ac = null;
let micStream = null;
let analyser = null;
let floatBuf = null;
let meterTimer = null;

let recorder = null;
let recChunks = [];
let recMime = '';

let listening = false;
let speaking = false;
let speechFrames = 0;
let silenceFrames = 0;
let recordingActive = false;
let utterStartTs = 0;

function dbfs_of_frame(buf) {
  let sum = 0;
  for (let i=0; i<buf.length; i++) {
    const s = buf[i];
    sum += s*s;
  }
  const rms = Math.sqrt(sum / buf.length + 1e-12);
  const db = 20 * Math.log10(rms);
  return db; // [-Infinity, 0]
}

async function initVAD() {
  if (!ac) ac = new (window.AudioContext || window.webkitAudioContext)();
  if (!micStream) micStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true } });
  const src = ac.createMediaStreamSource(micStream);
  analyser = ac.createAnalyser();
  analyser.fftSize = 1024;
  analyser.smoothingTimeConstant = 0.05;
  floatBuf = new Float32Array(analyser.fftSize);
  src.connect(analyser);

  // Prepare MediaRecorder for the same mic stream
  recMime = pickMimeType();
  recorder = new MediaRecorder(micStream, recMime ? { mimeType: recMime } : {});
  recorder.ondataavailable = (e) => { if (e.data && e.data.size > 0) recChunks.push(e.data); };
  recorder.onstop = onRecordingStop;

  hintEl.textContent = 'Listening‚Ä¶ start speaking to begin.';
  setVADState('Listening', true);

  listening = true;
  speechFrames = 0;
  silenceFrames = 0;
  meterTimer = setInterval(pollVAD, VAD_CFG.pollMs);
}

function setVADState(label, on) {
  vadStatePill.textContent = label;
  vadStatePill.classList.toggle('on', on);
  vadStatePill.classList.toggle('off', !on);
  toggleVADBtn.classList.toggle('on', on);
  toggleVADBtn.classList.toggle('off', !on);
}

function pickMimeType() {
  const cands = ['audio/webm;codecs=opus','audio/ogg;codecs=opus','audio/webm','audio/ogg','audio/wav'];
  for (const c of cands) if (MediaRecorder.isTypeSupported(c)) return c;
  return '';
}

function startRecordingNow() {
  if (recordingActive) return;
  recChunks = [];
  recorder.start();
  utterStartTs = performance.now();
  recordingActive = true;
  setVADState('Recording‚Ä¶', true);
  hintEl.textContent = 'Recording‚Ä¶ pause to finish.';
}

function stopRecordingNow() {
  if (!recordingActive) return;
  recordingActive = false;
  try { recorder.stop(); } catch {}
  setVADState('Processing‚Ä¶', true);
  hintEl.textContent = 'Transcribing‚Ä¶';
}

async function onRecordingStop() {
  // Send to /stt (Whisper)
  try {
    const blob = new Blob(recChunks, { type: recMime || recChunks[0]?.type || 'audio/webm' });
    const fd = new FormData();
    fd.append('file', blob, 'speech.webm');
    const server = srvEl.value.replace(/\/+$/, '');
    const res = await fetch(server + '/stt', { method:'POST', body: fd });
    if (!res.ok) throw new Error(await res.text());
    const { text } = await res.json();
    if (text && text.trim().length) {
      appendBubble('user', text.trim());
      const reply = await sendToJetson(text.trim());
      appendBubble('assistant', reply);
      speak(reply);
    } else {
      appendBubble('system', 'Silence or unrecognized speech.');
    }
  } catch (e) {
    appendBubble('system', 'STT error: ' + e.message);
  } finally {
    // Return to listening
    setVADState('Listening', true);
    hintEl.textContent = 'Listening‚Ä¶';
  }
}

function pollVAD() {
  if (!analyser || !floatBuf) return;
  analyser.getFloatTimeDomainData(floatBuf);
  const db = dbfs_of_frame(floatBuf);

  // If TTS is currently speaking, we can optionally suppress VAD (echo).
  // Simple heuristic: pause listening during speech synthesis queue.
  speaking = speechSynthesis.speaking;
  if (speaking) {
    speechFrames = 0;
    silenceFrames = 0;
    return; // skip VAD while TTS is active
  }

  // State machine:
  if (!recordingActive) {
    // WAITING FOR SPEECH
    if (db > VAD_CFG.startDb) {
      speechFrames++;
      if (speechFrames >= VAD_CFG.startFrames) {
        startRecordingNow();
        speechFrames = 0;
        silenceFrames = 0;
      }
    } else {
      speechFrames = 0;
    }
  } else {
    // RECORDING; WAIT FOR SILENCE
    if (db < VAD_CFG.stopDb) {
      silenceFrames++;
      const durMs = performance.now() - utterStartTs;
      if (silenceFrames >= VAD_CFG.stopFrames && durMs >= VAD_CFG.minSpeakMs) {
        stopRecordingNow();
        silenceFrames = 0;
        speechFrames = 0;
      }
    } else {
      silenceFrames = 0;
    }
  }
}

/* ------------------------- Controls ------------------------- */
toggleVADBtn.onclick = async () => {
  if (!listening) {
    toggleVADBtn.disabled = true;
    try {
      await initVAD(); // prompts for mic permission (user gesture)
      toggleVADBtn.textContent = 'üõë Stop VAD';
      setVADState('Listening', true);
    } catch (e) {
      appendBubble('system', 'Mic error: ' + e.message);
      setVADState('Idle', false);
    } finally {
      toggleVADBtn.disabled = false;
    }
  } else {
    // stop listening
    listening = false;
    setVADState('Idle', false);
    toggleVADBtn.textContent = 'üé§ Start VAD';
    hintEl.textContent = 'Status: not listening.';
    try { clearInterval(meterTimer); } catch {}
    try { if (recorder && recorder.state === 'recording') recorder.stop(); } catch {}
    try { if (ac && ac.state !== 'closed') ac.close(); } catch {}
    ac = null; analyser = null; micStream = null; recorder = null;
  }
};
</script>
</body>
</html>